# ğŸ§  Tutorial: Sentence-BERT (sBERT) com Cosine Similarity Loss e Triplet Loss

Este repositÃ³rio demonstra como treinar e avaliar modelos Sentence-BERT (sBERT) para medir similaridade entre sentenÃ§as em portuguÃªs, utilizando duas funÃ§Ãµes de perda distintas:
- **Cosine Similarity Loss** e **Triplet Loss**, da biblioteca [`sentence-transformers`](https://www.sbert.net/).

---

## ğŸ¯ Objetivos

- Entender como o **sBERT** transforma sentenÃ§as em **embeddings**.
- Compreender o papel de uma funÃ§Ã£o de perda (loss function) no treinamento de modelos de machine learning.
- Explorar os conceitos e implementaÃ§Ã£o da **Cosine Similarity Loss** e da **Triplet Loss**.
- Treinar modelos supervisionados para **classificar pares de sentenÃ§as** como **semelhantes (1)** ou **diferentes (0)**.
- Avaliar o desempenho dos modelos com mÃ©tricas como **AUC**, **Accuracy** e **F1-score**.

---

## ğŸ“š Conceitos Fundamentais

### ğŸ”¹ O que Ã© Sentence-BERT?

O **Sentence-BERT (sBERT)** Ã© uma variaÃ§Ã£o do modelo BERT ajustada para **comparar sentenÃ§as**.
Ele transforma frases em vetores numÃ©ricos **(embeddings)** que capturam o seu significado semÃ¢ntico.

Por exemplo:
- *â€œO gato dorme.â€* e *â€œO felino estÃ¡ descansando.â€* terÃ£o embeddings **prÃ³ximos**.
- *â€œO gato dorme.â€* e *â€œO carro Ã© vermelho.â€* terÃ£o embeddings **distantes**.

---

## âš–ï¸ FunÃ§Ãµes de Perda

### ğŸ”¹ O que Ã© uma FunÃ§Ã£o de Perda?

A **funÃ§Ã£o de perda** (ou *loss function*) mede o quanto as previsÃµes do modelo estÃ£o **erradas** em relaÃ§Ã£o ao valor **esperado**.
Durante o treinamento, o modelo tenta **minimizar** essa perda, ajustando seus pesos internos a cada iteraÃ§Ã£o.

â¡ï¸ Assim, a funÃ§Ã£o de perda Ã© o mecanismo de aprendizado, ela informa ao modelo como melhorar.

### ğŸ”¹ Cosine Similarity Loss

A **Cosine Similarity Loss** ensina o modelo a produzir embeddings de sentenÃ§as de forma que o cosseno entre eles reflita sua **similaridade semÃ¢ntica**.

- Se duas sentenÃ§as tÃªm significados parecidos, o cosseno entre seus embeddings deve ser prÃ³ximo de 1.
- Se sÃ£o diferentes, o cosseno deve ser prÃ³ximo de -1.

### ğŸ’¡ FÃ³rmula da Cosine Similarity Loss:
$$
L = 1 - \cos(A, B)
$$

Durante o treinamento, o modelo ajusta seus parÃ¢metros para **maximizar a similaridade** entre embeddings de sentenÃ§as que sÃ£o semanticamente prÃ³ximas e **minimizar a similaridade** entre as que nÃ£o sÃ£o.

---

### ğŸ”º Triplet Loss

A **Triplet Loss** compara trÃªs frases por vez:

- **Anchor (A)** â€“ frase base
- **Positive (P)** â€“ frase parecida com A
- **Negative (N)** â€“ frase diferente de A

### ğŸ’¡ FÃ³rmula da Triplet Loss:
$$
L = \max(0, \; d(A, P) - d(A, N) + \text{margin})
$$

Isso forÃ§a os embeddings de A e P a ficarem mais **prÃ³ximos**, e os de A e N, mais **distantes**.

---

### ğŸ§© Contrastive Loss

A Contrastive Loss Ã© usada quando o dataset contÃ©m pares rotulados com 0 ou 1:
- 1 â†’ sentenÃ§as semelhantes (devem estar prÃ³ximas);
- 0 â†’ sentenÃ§as diferentes (devem estar distantes).

Em vez de comparar triplas como na Triplet Loss, ela compara apenas pares, penalizando o modelo de acordo com a **distÃ¢ncia entre os embeddings** e o **rÃ³tulo verdadeiro**.

### ğŸ’¡ FÃ³rmula da Contrastive Loss:
$$
L = (1 - Y) \cdot D^2 + Y \cdot \max(0, \; m - D)^2
$$

Onde:
- **ğ‘Œ** Ã© o rÃ³tulo (0 ou 1);
- **ğ·** Ã© a distÃ¢ncia entre os embeddings (geralmente Euclidiana);
- **ğ‘š** Ã© a margem mÃ­nima de separaÃ§Ã£o.

---

### ğŸ”¶ Multiple Negatives Ranking Loss (MNRL)

A **MultipleNegativesRankingLoss (MNRL)** Ã© uma evoluÃ§Ã£o moderna da *Contrastive Loss*, ela usa o **batch inteiro** como base para aprendizado, sem precisar criar pares ou triplas manualmente.

Durante o treinamento:
- Cada par positivo (A, P) dentro do batch Ã© considerado um exemplo **positivo**;
- Todas as outras sentenÃ§as no mesmo batch sÃ£o tratadas automaticamente como **negativas**.

Assim, o modelo aprende a:
- Maximizar a similaridade entre o par correto (A, P);
- Minimizar a similaridade com todas as outras combinaÃ§Ãµes (A, N).

### ğŸ’¡ FÃ³rmula da MNRL:
$$
L = -\log \frac{\exp(\cos(A, P))}{\sum_{N \in \text{batch}} \exp(\cos(A, N))}
$$

---

#### ğŸ“Š Comparativo geral

| FunÃ§Ã£o de Perda           | Estrutura de entrada       | Ideal para                         | IntuiÃ§Ã£o principal                                    |
| ------------------------- | -------------------------- | ---------------------------------- | ----------------------------------------------------- |
| **CosineSimilarityLoss**  | Pares com score (contÃ­nuo) | Similaridade contÃ­nua (0â€“1)/(0-5)  | Aproximar embeddings proporcionalmente ao score       |
| **ContrastiveLoss**       | Pares com label (0/1)      | ClassificaÃ§Ã£o binÃ¡ria              | Aproximar pares positivos, afastar negativos          |
| **TripletLoss**           | Triplas (A, P, N)          | RelaÃ§Ãµes relativas entre exemplos  | A Ã© mais parecido com P do que com N                  |
| **MNRL**                  | Pares positivos            | BinÃ¡rio com batches grandes        | Usa todos os pares do batch como negativos implÃ­citos |

---

## ğŸ”§ PrÃ©-requisitos
- Python: 3.11.5 (ou superior)

---

## âš™ï¸ InstalaÃ§Ã£o e configuraÃ§Ã£o

```bash
git clone https://github.com/leovianaf/sbert-contrastive-tutorial.git
cd sbert-contrastive-tutorial
```

Acessando o repositÃ³rio, vocÃª deve criar seu ambiente virtual, ativÃ¡-lo e instalar as dependÃªncias:
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Com o ambiente virtual configurado, vocÃª deve utilizÃ¡-lo para executar os notebooks.

---

## ğŸš€ Treinamento
O notebook de treinamento utilizando a **Cosine Similarity Loss** pode ser acessado aqui: [`train_sbert_cosine.ipynb`](notebooks/train_sbert_cosine.ipynb)

O notebook de treinamento utilizando a **TripletLoss** pode ser acessado aqui: [`train_sbert_triplet.ipynb`](notebooks/train_sbert_triplet.ipynb)

---

## ğŸ“ˆ AvaliaÃ§Ã£o
O notebook de avaliaÃ§Ã£o do treinamento pode ser acessado aqui: [`evaluate_sbert.ipynb`](notebooks/evaluate_sbert.ipynb)

---

## ğŸ“ˆ MÃ©tricas de desempenho

| Modelo          | Loss Function        | Accuracy | AUC   | F1-score | ObservaÃ§Ã£o                                   |
|-----------------|----------------------|----------|-------|----------|----------------------------------------------|
| sBERT - Cosine  | CosineSimilarityLoss | 0.804    | 0.820 | 0.516    | Modelo com boa separaÃ§Ã£o geral               |
| sBERT - Triplet | TripletLoss          | 0.779    | 0.814 | 0.509    | Boa convergÃªncia, mas precisa de refinamento |

---

## ğŸ“œ LicenÃ§a

Este projeto estÃ¡ licenciado sob os termos da **MIT License**.
VocÃª Ã© livre para usar, modificar e distribuir este cÃ³digo, desde que mantenha o aviso de copyright.
